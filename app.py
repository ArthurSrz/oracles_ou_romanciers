import streamlit as st
import requests
import json
import re
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import pandas as pd
import time

st.set_page_config(
    page_title="G√©n√©rateur de R√©cits Parall√®les",
    page_icon="üìö",
    layout="wide"
)

st.title("üìö G√©n√©rateur de R√©cits Parall√®les")
st.markdown("*Des r√©cits alternatifs qui √©mergent d'une r√©alit√© statistique construite sur les vestiges de notre pass√© collectif.*")

# Configuration des √©poques historiques
EPOCHS = {
    "Renaissance (1400-1600)": {
        "description": "√âpoque de renouveau artistique et scientifique en Europe",
        "keywords": ["art", "science", "humanisme", "exploration", "inventions"],
        "context": "√Ä la Renaissance, l'Europe conna√Æt un renouveau artistique, scientifique et culturel. Les grandes d√©couvertes transforment la vision du monde."
    },
    "R√©volution fran√ßaise (1789-1799)": {
        "description": "P√©riode de bouleversements politiques et sociaux en France",
        "keywords": ["r√©volution", "libert√©", "√©galit√©", "fraternit√©", "r√©publique"],
        "context": "La R√©volution fran√ßaise marque la fin de l'Ancien R√©gime et l'√©mergence de nouveaux id√©aux d√©mocratiques."
    },
    "R√©volution industrielle (1760-1840)": {
        "description": "Transformation √©conomique et sociale par la m√©canisation",
        "keywords": ["industrie", "machines", "vapeur", "usines", "urbanisation"],
        "context": "La r√©volution industrielle transforme radicalement les modes de production et la soci√©t√© europ√©enne."
    },
    "Belle √âpoque (1871-1914)": {
        "description": "P√©riode de prosp√©rit√© et d'innovations en Europe",
        "keywords": ["progr√®s", "innovations", "√©lectricit√©", "automobile", "cin√©ma"],
        "context": "La Belle √âpoque est marqu√©e par l'optimisme, les innovations techniques et l'√©panouissement culturel."
    },
    "Ann√©es folles (1920-1929)": {
        "description": "D√©cennie d'euphorie et de modernit√© apr√®s la Grande Guerre",
        "keywords": ["jazz", "modernit√©", "lib√©ration", "√©conomie", "arts"],
        "context": "Les Ann√©es folles sont une p√©riode d'effervescence culturelle et de prosp√©rit√© √©conomique."
    }
}

# Sidebar pour les param√®tres
st.sidebar.header("‚öôÔ∏è Param√®tres de g√©n√©ration")

# S√©lection de l'√©poque
selected_epoch = st.sidebar.selectbox(
    "Choisissez une √©poque historique :",
    list(EPOCHS.keys())
)

st.sidebar.markdown(f"**Description :** {EPOCHS[selected_epoch]['description']}")

# Param√®tres de divergence
st.sidebar.subheader("üîÄ Param√®tres de divergence")

tech_level = st.sidebar.slider(
    "Niveau technologique alternatif",
    min_value=0,
    max_value=100,
    value=30,
    help="0 = technologies de l'√©poque, 100 = technologies tr√®s avanc√©es"
)

social_change = st.sidebar.slider(
    "Changements sociaux/politiques",
    min_value=0,
    max_value=100,
    value=40,
    help="0 = soci√©t√© identique, 100 = soci√©t√© radicalement diff√©rente"
)

fantasy_elements = st.sidebar.slider(
    "√âl√©ments fantastiques subtils",
    min_value=0,
    max_value=100,
    value=20,
    help="0 = r√©alisme pur, 100 = √©l√©ments magiques/fantastiques"
)

story_length = st.sidebar.selectbox(
    "Longueur du r√©cit :",
    ["Court (100-200 mots)", "Moyen (300-500 mots)", "Long (600-800 mots)"]
)

# Configuration Hugging Face
HF_MODEL = "HuggingFaceTB/SmolLM3-3B"

# Fonction pour nettoyer les thinking tokens
def clean_thinking_tokens(text):
    """Extrait le contenu narratif fran√ßais des thinking tokens"""
    import re
    if not text:
        return text

    # Chercher du contenu narratif fran√ßais dans toutes les balises <think>
    story_parts = []

    # Extraire tout le contenu des balises <think>...</think>
    think_matches = re.findall(r'<think>(.*?)</think>', text, flags=re.DOTALL)

    # Si pas de balises ferm√©es, chercher une balise ouverte
    if not think_matches:
        think_match = re.search(r'<think>(.*)', text, flags=re.DOTALL)
        if think_match:
            think_matches = [think_match.group(1)]

    # Analyser chaque bloc de thinking pour extraire UNIQUEMENT les parties narratives fran√ßaises
    for think_content in think_matches:
        lines = think_content.split('\n')
        french_started = False

        for line in lines:
            line = line.strip()

            # D√©tecter le d√©but du r√©cit fran√ßais (souvent apr√®s des analyses en anglais)
            if not french_started:
                # Chercher des phrases qui commencent clairement du fran√ßais
                if (len(line) > 20 and
                    (line.startswith('√Ä ') or line.startswith('En ') or line.startswith('Dans ') or
                     line.startswith('Le ') or line.startswith('La ') or line.startswith('Les ') or
                     line.startswith('Un ') or line.startswith('Une ')) and
                    not any(eng in line.lower() for eng in ['in florence', 'check the word', 'technical aspect', 'that seems', 'need to make'])):
                    french_started = True
                    story_parts.append(line)
                continue

            # Une fois le fran√ßais commenc√©, continuer tant qu'on est en fran√ßais
            if french_started:
                # Arr√™ter si on retombe sur de l'anglais d'analyse
                if any(phrase in line.lower() for phrase in ['check the word', 'word count', 'technical aspect', 'that seems', 'need to make', 'fits the time']):
                    break

                # Continuer si c'est du fran√ßais narratif
                if (len(line) > 10 and
                    any(word in line.lower() for word in ['dans', '√©tait', 'sur', 'avec', 'pour', 'une', 'le', 'la', 'les', 'des', 'du', 'de', 'mais', 'alors']) and
                    not any(phrase in line.lower() for phrase in ['i need', 'i should', 'let me', 'maybe', 'perhaps', 'i think', 'okay'])):
                    story_parts.append(line)
                elif line == '':  # Ligne vide acceptable
                    story_parts.append('')

    # Aussi chercher du contenu fran√ßais en dehors des balises
    outside_think = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    outside_think = re.sub(r'<think>.*', '', outside_think, flags=re.DOTALL)

    lines = outside_think.split('\n')
    for line in lines:
        line = line.strip()
        if (len(line) > 30 and
            any(word in line.lower() for word in ['dans', '√©tait', 'sur', 'avec', 'pour', 'une', 'le', 'la', 'les', 'des', 'du', 'de']) and
            not any(phrase in line.lower() for phrase in ['i need', 'i should', 'let me', 'maybe', 'perhaps', 'i think', 'okay'])):
            story_parts.append(line)

    # Assembler le r√©cit
    if story_parts:
        cleaned = '\n\n'.join(story_parts)
        # Nettoyer les espaces multiples
        cleaned = re.sub(r'  +', ' ', cleaned)
        return cleaned.strip()

    # Si rien trouv√©, fallback sur l'ancien algorithme
    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
    cleaned = re.sub(r'<think>.*', '', cleaned, flags=re.DOTALL)
    return cleaned.strip()

# Fonction pour appeler l'API Hugging Face
def call_huggingface_api(prompt, max_retries=3):
    print(f"üîç DEBUG: D√©but call_huggingface_api avec prompt: {prompt[:100]}...")

    # Utilisation du token depuis les secrets Streamlit
    api_token = st.secrets.get("HUGGINGFACE_API_TOKEN", "")
    print(f"üîç DEBUG: Token trouv√©: {bool(api_token)} (longueur: {len(api_token) if api_token else 0})")

    if not api_token:
        print("‚ùå DEBUG: Pas de token trouv√©")
        st.error("Token Hugging Face manquant. Veuillez configurer HUGGINGFACE_API_TOKEN dans les secrets.")
        return None

    try:
        # Import Hugging Face InferenceClient
        from huggingface_hub import InferenceClient

        # Cr√©ation du client Hugging Face
        client = InferenceClient(
            provider="hf-inference",
            api_key=api_token,
        )
        print(f"üîç DEBUG: Client Hugging Face configur√© avec provider hf-inference")

        for attempt in range(max_retries):
            try:
                print(f"üîç DEBUG: Tentative {attempt + 1}/{max_retries} avec le mod√®le {HF_MODEL}")

                # Appel √† l'API avec le client Hugging Face (non-streaming)
                # Utiliser un exemple pour "apprendre" au mod√®le √† r√©pondre correctement
                completion = client.chat.completions.create(
                    model=HF_MODEL,
                    messages=[
                        {
                            "role": "user",
                            "content": "√âcris une courte histoire de 50 mots sur la Renaissance."
                        },
                        {
                            "role": "assistant",
                            "content": "<think>\nJe dois √©crire une histoire courte sur la Renaissance. Je vais me concentrer sur un artiste √† Florence.\n</think>\n\nEn cette ann√©e 1503 √† Florence, Lorenzo observait son ma√Ætre Leonardo peindre. Les pinceaux dansaient sur la toile, capturant la lumi√®re comme jamais auparavant. \"L'art r√©v√®le la v√©rit√©\", murmura le ma√Ætre. Lorenzo comprit alors que cette √©poque de renouveau transformait non seulement l'art, mais l'√¢me humaine elle-m√™me."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000,
                    temperature=0.7,
                    top_p=1.0,
                    stream=False
                )

                generated = completion.choices[0].message.content
                if generated:
                    # Nettoyer les thinking tokens
                    cleaned_text = clean_thinking_tokens(generated)

                    if cleaned_text and len(cleaned_text) > 20:  # V√©rifier qu'il y a du contenu substantiel
                        print(f"‚úÖ DEBUG: Texte g√©n√©r√©: {cleaned_text[:100]}...")
                        return cleaned_text
                    else:
                        print(f"‚ö†Ô∏è DEBUG: Texte vide ou trop court apr√®s nettoyage, utilisation du fallback")
                        return generate_fallback_story(prompt)
                else:
                    print(f"‚ö†Ô∏è DEBUG: R√©ponse vide")

            except Exception as e:
                print(f"üí• DEBUG: Erreur tentative {attempt + 1}: {str(e)}")
                if "503" in str(e) or "loading" in str(e).lower():
                    st.warning(f"Mod√®le en cours de chargement... Tentative {attempt + 1}/{max_retries}")
                    time.sleep(20)
                    continue
                elif "429" in str(e) or "rate" in str(e).lower():
                    st.warning(f"Limite de taux atteinte. Tentative {attempt + 1}/{max_retries}")
                    time.sleep(30)
                    continue
                else:
                    st.warning(f"Erreur: {str(e)}")
                    if attempt == max_retries - 1:
                        break
                    time.sleep(5)

    except ImportError:
        print("‚ùå DEBUG: Module huggingface_hub non disponible")
        st.error("Module huggingface_hub non install√©. Utilisez: pip install huggingface_hub")
        return None
    except Exception as e:
        print(f"üí• DEBUG: Erreur configuration client: {str(e)}")
        st.error(f"Erreur configuration API: {str(e)}")
        return None

    # Si tous les essais √©chouent, g√©n√©ration de fallback
    print("üîÑ DEBUG: Utilisation du fallback")
    return generate_fallback_story(prompt)

# Fonction de fallback pour g√©n√©rer une histoire simple
def generate_fallback_story(prompt):
    epoch_stories = {
        "Renaissance": "En cette √©poque de renouveau, un artiste florentin d√©couvrit dans son atelier une machine √©trange, aux engrenages d'une pr√©cision inou√Øe. Cette invention, l√©gu√©e par un myst√©rieux alchimiste, permettait de capturer la lumi√®re m√™me et de la transformer en pigments aux couleurs impossibles. Ses ≈ìuvres, d'une beaut√© surnaturelle, attir√®rent l'attention de m√©c√®nes venus de contr√©es lointaines. Mais l'artiste r√©alisa bient√¥t que chaque toile peinte avec ces couleurs magiques volait un fragment de r√©alit√© au monde, cr√©ant des √©chos entre les dimensions.",

        "R√©volution fran√ßaise": "Dans les rues de Paris r√©volutionnaire, une imprimerie clandestine produisait des pamphlets aux propri√©t√©s extraordinaires. L'encre, m√©lang√©e avec des herbes rares trouv√©es dans les jardins royaux abandonn√©s, rendait les mots litt√©ralement convaincants - quiconque lisait ces textes se trouvait irr√©sistiblement pouss√© √† agir selon leur contenu. Les r√©volutionnaires utilis√®rent ce pouvoir avec parcimonie, conscients que leur libert√© nouvellement acquise d√©pendait de la volont√© authentique du peuple, non de la magie de l'encre.",

        "R√©volution industrielle": "Les machines √† vapeur de cette Manchester alternative fonctionnaient non pas au charbon, mais aux r√™ves collect√©s dans les quartiers ouvriers. Des collecteurs nocturnes parcouraient les rues, r√©cup√©rant dans des fioles de cristal les songes abandonn√©s par les travailleurs √©puis√©s. Ces r√™ves, une fois distill√©s, produisaient une √©nergie pure et in√©puisable. Mais quand les ouvriers cess√®rent de r√™ver, priv√©s de leurs aspirations, les machines s'arr√™t√®rent une √† une, et la soci√©t√© dut repenser son rapport au progr√®s.",

        "Belle √âpoque": "L'Exposition universelle de Paris accueillait cette ann√©e-l√† un pavillon secret, visible seulement √† la tomb√©e du jour. Les inventions expos√©es d√©fiaient les lois de la physique : des automobiles volantes aliment√©es par la musique des cabarets, des t√©l√©phones permettant de converser avec les morts, des photographies capturant non pas les visages mais les √©motions. Les visiteurs, √©bahis, repartaient avec la certitude qu'un monde nouveau √©tait n√©, o√π la science et la po√©sie ne faisaient qu'un.",

        "Ann√©es folles": "Dans les clubs de jazz de Montmartre, la musique avait acquis des propri√©t√©s alchimiques. Les notes de saxophone transformaient litt√©ralement l'atmosph√®re, rendant l'air plus l√©ger, permettant aux danseurs de d√©fier la gravit√© quelques instants. Les musiciens, conscients de leur pouvoir, cr√©aient des m√©lodies capables d'effacer temporairement les traumatismes de la Grande Guerre. Mais ils d√©couvrirent bient√¥t que cette magie avait un prix : elle consumait lentement leur propre m√©moire, les condamnant √† rejouer √©ternellement les m√™mes airs."
    }

    # Retourne une histoire pr√©d√©finie selon l'√©poque
    for epoch_key, story in epoch_stories.items():
        if epoch_key.lower() in prompt.lower():
            return story

    return epoch_stories["Renaissance"]  # Histoire par d√©faut

# Fonction pour g√©n√©rer le prompt
def generate_prompt(epoch, tech, social, fantasy, length):
    epoch_data = EPOCHS[epoch]

    length_instruction = {
        "Court (100-200 mots)": "un court r√©cit de 100 √† 200 mots",
        "Moyen (300-500 mots)": "un r√©cit de 300 √† 500 mots",
        "Long (600-800 mots)": "un r√©cit d√©taill√© de 600 √† 800 mots"
    }

    tech_description = ""
    if tech > 70:
        tech_description = "avec des technologies tr√®s avanc√©es pour l'√©poque"
    elif tech > 40:
        tech_description = "avec quelques innovations technologiques"
    elif tech > 10:
        tech_description = "avec de l√©g√®res am√©liorations techniques"

    social_description = ""
    if social > 70:
        social_description = "dans une soci√©t√© aux structures radicalement diff√©rentes"
    elif social > 40:
        social_description = "avec des changements sociaux notables"
    elif social > 10:
        social_description = "avec quelques modifications sociales"

    fantasy_description = ""
    if fantasy > 70:
        fantasy_description = "int√©grant des √©l√©ments magiques subtils"
    elif fantasy > 40:
        fantasy_description = "avec des ph√©nom√®nes inexpliqu√©s"
    elif fantasy > 10:
        fantasy_description = "avec une l√©g√®re touche de myst√®re"

    prompt = f"""Histoire: {length_instruction[length]} se d√©roulant pendant {epoch.split('(')[0].strip()} {tech_description} {social_description} {fantasy_description}.

Contexte: {epoch_data['context']}

R√©cit:"""

    return prompt

# Fonction pour analyser le texte g√©n√©r√©
def analyze_text(text):
    # Comptage des mots
    words = re.findall(r'\b\w+\b', text.lower())
    word_count = len(words)

    # Mots les plus fr√©quents
    word_freq = Counter(words)
    common_words = word_freq.most_common(10)

    # D√©tection d'√©l√©ments "parall√®les" vs r√©alistes
    parallel_indicators = [
        'alternative', 'diff√©rent', 'inhabituel', '√©trange', 'myst√©rieux',
        'inexpliqu√©', 'nouveau', 'r√©volutionnaire', 'impossible', 'magique'
    ]

    parallel_score = sum(1 for word in words if word in parallel_indicators)
    parallel_percentage = (parallel_score / word_count) * 100 if word_count > 0 else 0

    return {
        'word_count': word_count,
        'common_words': common_words,
        'parallel_score': parallel_percentage
    }

# Interface principale
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üìñ G√©n√©ration de r√©cit")

    if st.button("üé≤ G√©n√©rer un r√©cit parall√®le", type="primary"):
        with st.spinner("G√©n√©ration du r√©cit en cours..."):
            try:
                print(f"üöÄ DEBUG: Bouton cliqu√© - G√©n√©ration d√©marr√©e")
                print(f"üîç DEBUG: Param√®tres - √âpoque: {selected_epoch}, Tech: {tech_level}, Social: {social_change}, Fantasy: {fantasy_elements}")

                prompt = generate_prompt(selected_epoch, tech_level, social_change, fantasy_elements, story_length)
                print(f"üìù DEBUG: Prompt g√©n√©r√©: {prompt[:200]}...")

                # Appel √† l'API Hugging Face ou fallback
                print("üåê DEBUG: Appel de l'API Hugging Face...")
                generated_story = call_huggingface_api(prompt)

                if not generated_story:
                    print("‚ö†Ô∏è DEBUG: API a retourn√© None, utilisation du fallback")
                    # Si l'API √©choue, utilise le fallback
                    generated_story = generate_fallback_story(prompt)
                    st.info("üé≠ Histoire g√©n√©r√©e en mode hors-ligne (API Hugging Face indisponible)")
                else:
                    print(f"‚úÖ DEBUG: Histoire g√©n√©r√©e avec succ√®s: {len(generated_story)} caract√®res")

                # Stockage dans la session avec historique
                print("üíæ DEBUG: Stockage dans la session...")

                # Initialiser l'historique s'il n'existe pas
                if 'story_history' not in st.session_state:
                    st.session_state.story_history = []

                # Cr√©er l'entr√©e d'historique
                story_entry = {
                    'story': generated_story,
                    'epoch': selected_epoch,
                    'tech_level': tech_level,
                    'social_change': social_change,
                    'fantasy_elements': fantasy_elements,
                    'story_length': story_length,
                    'timestamp': pd.Timestamp.now(),
                    'analysis': analyze_text(generated_story)
                }

                # Ajouter au d√©but de l'historique (le plus r√©cent en premier)
                st.session_state.story_history.insert(0, story_entry)

                # Limiter l'historique √† 10 r√©cits pour √©viter l'encombrement
                if len(st.session_state.story_history) > 10:
                    st.session_state.story_history = st.session_state.story_history[:10]

                # Garder les variables pour l'affichage principal
                st.session_state.current_story = generated_story
                st.session_state.current_analysis = analyze_text(generated_story)
                print("‚úÖ DEBUG: G√©n√©ration termin√©e avec succ√®s")

            except Exception as e:
                print(f"üí• DEBUG: Exception dans le bouton: {str(e)}")
                import traceback
                print(f"üìç DEBUG: Traceback complet: {traceback.format_exc()}")

                st.error(f"Erreur lors de la g√©n√©ration : {str(e)}")
                # G√©n√©ration de fallback en cas d'erreur
                try:
                    prompt = generate_prompt(selected_epoch, tech_level, social_change, fantasy_elements, story_length)
                    generated_story = generate_fallback_story(prompt)

                    # Initialiser l'historique s'il n'existe pas
                    if 'story_history' not in st.session_state:
                        st.session_state.story_history = []

                    # Cr√©er l'entr√©e d'historique pour le fallback
                    story_entry = {
                        'story': generated_story,
                        'epoch': selected_epoch,
                        'tech_level': tech_level,
                        'social_change': social_change,
                        'fantasy_elements': fantasy_elements,
                        'story_length': story_length,
                        'timestamp': pd.Timestamp.now(),
                        'analysis': analyze_text(generated_story),
                        'is_fallback': True
                    }

                    st.session_state.story_history.insert(0, story_entry)

                    if len(st.session_state.story_history) > 10:
                        st.session_state.story_history = st.session_state.story_history[:10]

                    st.session_state.current_story = generated_story
                    st.session_state.current_analysis = analyze_text(generated_story)
                    st.info("üé≠ Histoire g√©n√©r√©e en mode hors-ligne")
                    print("üîÑ DEBUG: Fallback appliqu√© avec succ√®s")
                except Exception as fallback_error:
                    print(f"üí• DEBUG: Erreur m√™me dans le fallback: {str(fallback_error)}")
                    st.error(f"Erreur critique: {str(fallback_error)}")

    # Affichage du r√©cit g√©n√©r√©
    if hasattr(st.session_state, 'current_story'):
        st.subheader("üìú R√©cit g√©n√©r√©")
        st.write(st.session_state.current_story)

        # Bouton pour sauvegarder
        if st.button("üíæ Sauvegarder ce r√©cit"):
            try:
                with open(f"/Users/arthursarazin/Documents/oracles_ou_romanciers/recit_{selected_epoch.replace(' ', '_')}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.txt", "w", encoding='utf-8') as f:
                    f.write(f"√âpoque : {selected_epoch}\n")
                    f.write(f"Param√®tres : Tech={tech_level}, Social={social_change}, Fantasy={fantasy_elements}\n\n")
                    f.write(st.session_state.current_story)
                st.success("R√©cit sauvegard√© !")
            except Exception as e:
                st.error(f"Erreur lors de la sauvegarde : {str(e)}")

    # Section d'historique des r√©cits
    if hasattr(st.session_state, 'story_history') and st.session_state.story_history:
        st.markdown("---")
        st.header(f"üìö Historique des r√©cits ({len(st.session_state.story_history)} r√©cit{'s' if len(st.session_state.story_history) > 1 else ''})")

        # Boutons de gestion
        col_clear, col_info, col_spacer = st.columns([1, 2, 1])
        with col_clear:
            if st.button("üóëÔ∏è Vider l'historique"):
                st.session_state.story_history = []
                st.success("Historique vid√© !")
                st.rerun()
        with col_info:
            st.info("üí° Cliquez sur un r√©cit pour voir ses d√©tails et param√®tres")

        # Affichage de l'historique
        for i, entry in enumerate(st.session_state.story_history):
            # Cr√©er un titre avec emoji indicateur de nouveaut√©
            title_emoji = "üÜï" if i == 0 else "üìñ"
            title = f"{title_emoji} R√©cit {i+1} - {entry['epoch']} ({entry['timestamp'].strftime('%H:%M')})"

            with st.expander(title):
                # Affichage des param√®tres avec comparaison
                st.markdown("**Param√®tres utilis√©s :**")
                param_cols = st.columns(4)

                # Comparaison avec les param√®tres actuels
                current_params = {
                    'tech': tech_level,
                    'social': social_change,
                    'fantasy': fantasy_elements,
                    'length': story_length
                }

                with param_cols[0]:
                    delta = entry['tech_level'] - current_params['tech'] if i > 0 else None
                    st.metric("Tech", entry['tech_level'], delta=delta)
                with param_cols[1]:
                    delta = entry['social_change'] - current_params['social'] if i > 0 else None
                    st.metric("Social", entry['social_change'], delta=delta)
                with param_cols[2]:
                    delta = entry['fantasy_elements'] - current_params['fantasy'] if i > 0 else None
                    st.metric("Fantasy", entry['fantasy_elements'], delta=delta)
                with param_cols[3]:
                    st.write(f"**Longueur:** {entry['story_length']}")
                    if entry['story_length'] != current_params['length']:
                        st.caption(f"(Actuel: {current_params['length']})")

                # Indicateur de source
                if entry.get('is_fallback', False):
                    st.info("üé≠ R√©cit g√©n√©r√© en mode hors-ligne")

                # Le r√©cit
                st.markdown("**R√©cit :**")
                st.write(entry['story'])

                # Mini-analyse
                analysis = entry['analysis']
                st.markdown(f"**Analyse :** {analysis['word_count']} mots ‚Ä¢ Score de divergence : {analysis['parallel_score']:.1f}%")

                # Bouton pour recharger ce r√©cit comme actuel
                if st.button(f"üîÑ Recharger ce r√©cit", key=f"reload_{i}"):
                    st.session_state.current_story = entry['story']
                    st.session_state.current_analysis = entry['analysis']
                    st.success("R√©cit recharg√© dans l'affichage principal !")
                    st.rerun()

with col2:
    st.header("üìä Analyse du texte")

    if hasattr(st.session_state, 'current_analysis'):
        analysis = st.session_state.current_analysis

        # M√©triques
        st.metric("Nombre de mots", analysis['word_count'])
        st.metric("Score de divergence", f"{analysis['parallel_score']:.1f}%")

        # Mots les plus fr√©quents
        st.subheader("üî§ Mots les plus fr√©quents")
        for word, count in analysis['common_words'][:5]:
            st.write(f"‚Ä¢ **{word}** : {count}")

        # Nuage de mots
        if hasattr(st.session_state, 'current_story') and len(st.session_state.current_story) > 50:
            st.subheader("‚òÅÔ∏è Nuage de mots")
            try:
                wordcloud = WordCloud(
                    width=300,
                    height=200,
                    background_color='white',
                    colormap='viridis'
                ).generate(st.session_state.current_story)

                fig, ax = plt.subplots(figsize=(6, 4))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig)
            except Exception as e:
                st.write("Nuage de mots non disponible")

# Footer
st.markdown("---")
st.markdown("*Application d√©velopp√©e avec Streamlit et Ollama - Exploration des mondes parall√®les litt√©raires*")